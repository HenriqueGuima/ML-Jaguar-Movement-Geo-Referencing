{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jaguar Movement Databse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigating Jaguar Behavior in Relation to Meteorological Conditions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project aims to document, analyze and model jaguar movement patterns (Panthera Onca) from geo-referenced data of South and Central America and understanding how environmental factors influence their movement ecology. The main steps done are the preprocessing, to ensure data quality, consistency and usability to apply Machine Learning tasks.\n",
    "By taking advantage of a multi-year meteorological dataset, for five countries (Brazil, Paraguay, Argentina, Costa Rica, and Mexico), this project integrates the GPS data of several individual jaguars with said meteorlogical records."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Motivation\n",
    "\n",
    "Jaguars, as apex predators, play a critical role in ecosystem balance, but their movements remain poorly understood in the context of climate-driven habitat changes. Extreme weather events and shifting precipitation patterns threaten their habitats, making it imperative to identify how environmental conditions modulate behaviors such as hunting, territorial patrolling, and resting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from geopy.distance import geodesic\n",
    "import sqlite3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Guima\\AppData\\Local\\Temp\\ipykernel_11620\\961086142.py:4: DtypeWarning: Columns (5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv('H:/Study/IPCA/MIAA/MLA/TP2025/DataS1/jaguar_movement_data.csv')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Event_ID</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>location.long</th>\n",
       "      <th>location.lat</th>\n",
       "      <th>individual.taxon.canonical.name</th>\n",
       "      <th>tag.local.identifier</th>\n",
       "      <th>individual.local.identifier (ID)</th>\n",
       "      <th>study.name</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>6/15/10 22:43</td>\n",
       "      <td>-58.030128</td>\n",
       "      <td>-23.326947</td>\n",
       "      <td>Panthera onca</td>\n",
       "      <td>0-333005</td>\n",
       "      <td>1</td>\n",
       "      <td>Humid Chaco</td>\n",
       "      <td>Paraguay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>6/16/10 2:52</td>\n",
       "      <td>-58.030643</td>\n",
       "      <td>-23.328427</td>\n",
       "      <td>Panthera onca</td>\n",
       "      <td>0-333005</td>\n",
       "      <td>1</td>\n",
       "      <td>Humid Chaco</td>\n",
       "      <td>Paraguay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>6/16/10 22:36</td>\n",
       "      <td>-58.030472</td>\n",
       "      <td>-23.327311</td>\n",
       "      <td>Panthera onca</td>\n",
       "      <td>0-333005</td>\n",
       "      <td>1</td>\n",
       "      <td>Humid Chaco</td>\n",
       "      <td>Paraguay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>6/17/10 16:42</td>\n",
       "      <td>-58.027983</td>\n",
       "      <td>-23.309952</td>\n",
       "      <td>Panthera onca</td>\n",
       "      <td>0-333005</td>\n",
       "      <td>1</td>\n",
       "      <td>Humid Chaco</td>\n",
       "      <td>Paraguay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>6/17/10 20:37</td>\n",
       "      <td>-58.027747</td>\n",
       "      <td>-23.310006</td>\n",
       "      <td>Panthera onca</td>\n",
       "      <td>0-333005</td>\n",
       "      <td>1</td>\n",
       "      <td>Humid Chaco</td>\n",
       "      <td>Paraguay</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Event_ID      timestamp  location.long  location.lat  \\\n",
       "0       1.0  6/15/10 22:43     -58.030128    -23.326947   \n",
       "1       2.0   6/16/10 2:52     -58.030643    -23.328427   \n",
       "2       3.0  6/16/10 22:36     -58.030472    -23.327311   \n",
       "3       4.0  6/17/10 16:42     -58.027983    -23.309952   \n",
       "4       5.0  6/17/10 20:37     -58.027747    -23.310006   \n",
       "\n",
       "  individual.taxon.canonical.name tag.local.identifier  \\\n",
       "0                   Panthera onca             0-333005   \n",
       "1                   Panthera onca             0-333005   \n",
       "2                   Panthera onca             0-333005   \n",
       "3                   Panthera onca             0-333005   \n",
       "4                   Panthera onca             0-333005   \n",
       "\n",
       "   individual.local.identifier (ID)   study.name   country  \n",
       "0                                 1  Humid Chaco  Paraguay  \n",
       "1                                 1  Humid Chaco  Paraguay  \n",
       "2                                 1  Humid Chaco  Paraguay  \n",
       "3                                 1  Humid Chaco  Paraguay  \n",
       "4                                 1  Humid Chaco  Paraguay  "
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SAMPLE_SIZE = 20000\n",
    "\n",
    "# Load dataset\n",
    "data = pd.read_csv('H:/Study/IPCA/MIAA/MLA/TP2025/DataS1/jaguar_movement_data.csv')\n",
    "conn = sqlite3.connect('jaguar_data.db')\n",
    "\n",
    "# data = data.sample(SAMPLE_SIZE) \n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Event_ID                            0\n",
       "timestamp                           0\n",
       "location.long                       0\n",
       "location.lat                        0\n",
       "individual.taxon.canonical.name     0\n",
       "tag.local.identifier                0\n",
       "individual.local.identifier (ID)    0\n",
       "study.name                          0\n",
       "country                             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_cp = data.copy()\n",
    "data_cp.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fixing features names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['event_id', 'timestamp', 'location_long', 'location_lat',\n",
       "       'individual_taxon_canonical_name', 'tag_local_identifier',\n",
       "       'individual_local_identifier_ID', 'study_name', 'country'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fix features names Event_ID,timestamp,location.long,location.lat,individual.taxon.canonical.name,tag.local.identifier,individual.local.identifier (ID),study.name,country\n",
    "data_cp = data_cp.rename(columns={'Event_ID':'event_id','timestamp':'timestamp','location.long':'location_long','location.lat':'location_lat','individual.taxon.canonical.name':'individual_taxon_canonical_name','tag.local.identifier':'tag_local_identifier','individual.local.identifier (ID)':'individual_local_identifier_ID','study.name':'study_name','country':'country'})\n",
    "\n",
    "# Print features names\n",
    "data_cp.columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Guima\\AppData\\Local\\Temp\\ipykernel_11620\\3021486648.py:2: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  data_cp['timestamp'] = pd.to_datetime(data_cp['timestamp'])\n"
     ]
    }
   ],
   "source": [
    "# Parsing the timestamp column into a datetime format\n",
    "data_cp['timestamp'] = pd.to_datetime(data_cp['timestamp'])\n",
    "\n",
    "# Extract time of day, day of the week, month, etc., for temporal features.\n",
    "data_cp['hour'] = data_cp['timestamp'].dt.hour\n",
    "data_cp['day'] = data_cp['timestamp'].dt.day\n",
    "data_cp['month'] = data_cp['timestamp'].dt.month\n",
    "data_cp['year'] = data_cp['timestamp'].dt.year\n",
    "data_cp['dayofweek'] = data_cp['timestamp'].dt.dayofweek\n",
    "data_cp['date'] = data_cp['timestamp'].dt.date\n",
    "\n",
    "# Show unique values for day, month and year\n",
    "# print(data_cp['day'].unique())\n",
    "# print(data_cp['month'].unique())\n",
    "# print(data_cp['year'].unique())\n",
    "# print(data_cp['country'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['event_id', 'timestamp', 'location_long', 'location_lat',\n",
       "       'individual_taxon_canonical_name', 'tag_local_identifier',\n",
       "       'individual_local_identifier_ID', 'study_name', 'country', 'hour',\n",
       "       'day', 'month', 'year', 'dayofweek', 'date'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data_cp = data_cp.drop(['event_id', 'individual_local_identifier_ID', 'tag_local_identifier'], axis=1)\n",
    "\n",
    "data_cp.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Geospatial Data Processing"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating the distance between points using the Haversine Formula and group the data by tag_local_identifier to quantify travel distances and velocities. \n",
    "Engineered behavioral labels (hunting, movement, stopped) based on velocity thresholds.\n",
    "\n",
    "The top speed for a big cat (Jaguar) was considered to be of 50 mph or 80km/h for the labeling.\n",
    "\n",
    "Using the haversine formula, we were able to determine the distance between the coordinates along the Earth's surface.\n",
    "Although, since the Earth is not perfectly round, this formula may have an error up to 0.5%.\n",
    "\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Guima\\AppData\\Local\\Temp\\ipykernel_11620\\635299427.py:29: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  data_fe = data_fe.groupby('tag_local_identifier').apply(calculate_distances_for_animal)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>event_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>location_long</th>\n",
       "      <th>location_lat</th>\n",
       "      <th>individual_taxon_canonical_name</th>\n",
       "      <th>tag_local_identifier</th>\n",
       "      <th>individual_local_identifier_ID</th>\n",
       "      <th>study_name</th>\n",
       "      <th>country</th>\n",
       "      <th>hour</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>date</th>\n",
       "      <th>distance</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tag_local_identifier</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">35957</th>\n",
       "      <th>131870</th>\n",
       "      <td>131871.0</td>\n",
       "      <td>2015-10-12 00:00:00</td>\n",
       "      <td>-57.503400</td>\n",
       "      <td>-16.881275</td>\n",
       "      <td>Panthera onca</td>\n",
       "      <td>35957</td>\n",
       "      <td>117</td>\n",
       "      <td>Jaguar_Taiama</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>2015</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-10-12</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131871</th>\n",
       "      <td>131872.0</td>\n",
       "      <td>2015-10-12 01:00:00</td>\n",
       "      <td>-57.503355</td>\n",
       "      <td>-16.881304</td>\n",
       "      <td>Panthera onca</td>\n",
       "      <td>35957</td>\n",
       "      <td>117</td>\n",
       "      <td>Jaguar_Taiama</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>2015</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-10-12</td>\n",
       "      <td>0.0058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131872</th>\n",
       "      <td>131873.0</td>\n",
       "      <td>2015-10-12 02:01:00</td>\n",
       "      <td>-57.503327</td>\n",
       "      <td>-16.881216</td>\n",
       "      <td>Panthera onca</td>\n",
       "      <td>35957</td>\n",
       "      <td>117</td>\n",
       "      <td>Jaguar_Taiama</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>2015</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-10-12</td>\n",
       "      <td>0.0102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131873</th>\n",
       "      <td>131874.0</td>\n",
       "      <td>2015-10-12 03:00:00</td>\n",
       "      <td>-57.503302</td>\n",
       "      <td>-16.881220</td>\n",
       "      <td>Panthera onca</td>\n",
       "      <td>35957</td>\n",
       "      <td>117</td>\n",
       "      <td>Jaguar_Taiama</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>2015</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-10-12</td>\n",
       "      <td>0.0026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131874</th>\n",
       "      <td>131875.0</td>\n",
       "      <td>2015-10-12 04:00:00</td>\n",
       "      <td>-57.503297</td>\n",
       "      <td>-16.881144</td>\n",
       "      <td>Panthera onca</td>\n",
       "      <td>35957</td>\n",
       "      <td>117</td>\n",
       "      <td>Jaguar_Taiama</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>2015</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-10-12</td>\n",
       "      <td>0.0084</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             event_id           timestamp  location_long  \\\n",
       "tag_local_identifier                                                       \n",
       "35957                131870  131871.0 2015-10-12 00:00:00     -57.503400   \n",
       "                     131871  131872.0 2015-10-12 01:00:00     -57.503355   \n",
       "                     131872  131873.0 2015-10-12 02:01:00     -57.503327   \n",
       "                     131873  131874.0 2015-10-12 03:00:00     -57.503302   \n",
       "                     131874  131875.0 2015-10-12 04:00:00     -57.503297   \n",
       "\n",
       "                             location_lat individual_taxon_canonical_name  \\\n",
       "tag_local_identifier                                                        \n",
       "35957                131870    -16.881275                   Panthera onca   \n",
       "                     131871    -16.881304                   Panthera onca   \n",
       "                     131872    -16.881216                   Panthera onca   \n",
       "                     131873    -16.881220                   Panthera onca   \n",
       "                     131874    -16.881144                   Panthera onca   \n",
       "\n",
       "                            tag_local_identifier  \\\n",
       "tag_local_identifier                               \n",
       "35957                131870                35957   \n",
       "                     131871                35957   \n",
       "                     131872                35957   \n",
       "                     131873                35957   \n",
       "                     131874                35957   \n",
       "\n",
       "                             individual_local_identifier_ID     study_name  \\\n",
       "tag_local_identifier                                                         \n",
       "35957                131870                             117  Jaguar_Taiama   \n",
       "                     131871                             117  Jaguar_Taiama   \n",
       "                     131872                             117  Jaguar_Taiama   \n",
       "                     131873                             117  Jaguar_Taiama   \n",
       "                     131874                             117  Jaguar_Taiama   \n",
       "\n",
       "                            country  hour  day  month  year  dayofweek  \\\n",
       "tag_local_identifier                                                     \n",
       "35957                131870  Brazil     0   12     10  2015          0   \n",
       "                     131871  Brazil     1   12     10  2015          0   \n",
       "                     131872  Brazil     2   12     10  2015          0   \n",
       "                     131873  Brazil     3   12     10  2015          0   \n",
       "                     131874  Brazil     4   12     10  2015          0   \n",
       "\n",
       "                                   date  distance  \n",
       "tag_local_identifier                               \n",
       "35957                131870  2015-10-12       NaN  \n",
       "                     131871  2015-10-12    0.0058  \n",
       "                     131872  2015-10-12    0.0102  \n",
       "                     131873  2015-10-12    0.0026  \n",
       "                     131874  2015-10-12    0.0084  "
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_fe = data_cp.copy()\n",
    "\n",
    "data_fe['timestamp'] = pd.to_datetime(data_fe['timestamp'])\n",
    "\n",
    "# Define Haversine formula for distance calculation\n",
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    R = 6371000\n",
    "    phi1 = np.radians(lat1)\n",
    "    phi2 = np.radians(lat2)\n",
    "    delta_phi = np.radians(lat2 - lat1)\n",
    "    delta_lambda = np.radians(lon2 - lon1)\n",
    "\n",
    "    a = np.sin(delta_phi / 2)**2 + np.cos(phi1) * np.cos(phi2) * np.sin(delta_lambda / 2)**2\n",
    "    c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1 - a))\n",
    "\n",
    "    return R * c\n",
    "\n",
    "# Function to calculate distance only for the same animal\n",
    "def calculate_distances_for_animal(group):\n",
    "    group = group.sort_values('timestamp')\n",
    "    group['distance'] = haversine(\n",
    "        group['location_lat'].shift(),\n",
    "        group['location_long'].shift(),\n",
    "        group['location_lat'],\n",
    "        group['location_long']\n",
    "    )\n",
    "    return group\n",
    "\n",
    "data_fe = data_fe.groupby('tag_local_identifier').apply(calculate_distances_for_animal)\n",
    "\n",
    "# Convert distance to kilometers\n",
    "data_fe['distance'] = data_fe['distance'] / 1000\n",
    "data_fe['distance'] = data_fe['distance'].round(4)\n",
    "\n",
    "data_fe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating velocity, direction, and movement features based on location data (location.long, location.lat)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Labelling the movement based on the distance and velocity between each coordinates let's us determine what kind of behaviour our big cats were having. These were labelled as (movement, hunting, resting). To calculate the velocity, the difference between each timestamp in hours was extracted and measure the distance between each timestamp to kilometers. Based on the results we could argue that, since the jaguars are captivity inside reservations, there could not be much hunting activity since they would be fed by humans.\n",
    "\n",
    "velocity = distance / time\n",
    "\n",
    "Example: 1.5578(kilometers) / 60.033333 (hours) = 0.0259489 km/h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "movement > 0.5: 'hunting' (highest priority)\n",
    "\n",
    "0.1 < velocity ≤ 0.5: 'movement'\n",
    "\n",
    "= 0.0 'stopped'\n",
    "\n",
    "< 0.0: 'movement'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating velocity, direction, and movement features based on location data (location.long, location.lat).\n",
    "# Ensuring the time differece is i hours\n",
    "time_diff = data_fe['time_diff'] = data_fe['timestamp'].diff().dt.total_seconds() / 3600 # hours\n",
    "\n",
    "# print(data_fe.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             distance  time_diff  velocity\n",
      "tag_local_identifier                                      \n",
      "1494                 116327    0.0007   2.000000  0.000350\n",
      "36313                47208     0.0083   1.000000  0.008300\n",
      "                     46731     0.0224   1.016667  0.022033\n",
      "31936                23317     0.8918   0.500000  1.783600\n",
      "No5                  79671     0.7909   3.983333  0.198552\n"
     ]
    }
   ],
   "source": [
    "# Ensure the time difference is in hours\n",
    "data_fe['time_diff'] = data_fe['timestamp'].diff().dt.total_seconds() / 3600\n",
    "\n",
    "# Calculate velocity\n",
    "data_fe['velocity'] = data_fe['distance'] / data_fe['time_diff']\n",
    "\n",
    "print(data_fe[['distance', 'time_diff', 'velocity']].sample(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "movement\n",
      "resting          128189\n",
      "slow_movement      6373\n",
      "patrolling           14\n",
      "hunting               1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "JAGUAR_SPEEDS = {\n",
    "    'resting': (0, 1),\n",
    "    'slow_movement': (1, 10),\n",
    "    'patrolling': (10, 30),\n",
    "    'hunting': (30, 80)\n",
    "}\n",
    "\n",
    "data_fe['movement'] = np.select(\n",
    "    [\n",
    "        data_fe['velocity'].between(*JAGUAR_SPEEDS['resting']),\n",
    "        data_fe['velocity'].between(*JAGUAR_SPEEDS['slow_movement']),\n",
    "        data_fe['velocity'].between(*JAGUAR_SPEEDS['patrolling']),\n",
    "        data_fe['velocity'].between(*JAGUAR_SPEEDS['hunting'])\n",
    "    ],\n",
    "    [\n",
    "        'resting',\n",
    "        'slow_movement',\n",
    "        'patrolling',\n",
    "        'hunting'\n",
    "    ],\n",
    "    default='unknown'\n",
    ")\n",
    "\n",
    "data_fe = data_fe.dropna(subset=['distance', 'velocity'])\n",
    "data_fe['velocity'] = data_fe['velocity'].round(2)\n",
    "\n",
    "print(data_fe['movement'].value_counts())\n",
    "\n",
    "data_fe['direction'] = np.arctan2(data_fe['location_long'] - data_fe['location_long'].shift(), data_fe['location_lat'] - data_fe['location_lat'].shift())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deriving acceleration or changes in movement direction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "# Calculate acceleration as the change in velocity over time\n",
    "data_fe['acceleration'] = data_fe['velocity'].diff() / data_fe['time_diff']\n",
    "\n",
    "# Calculate change in direction\n",
    "data_fe['change_in_direction'] = data_fe['direction'].diff()\n",
    "\n",
    "# Drop rows with NaN values in acceleration and change_in_direction\n",
    "data_fe = data_fe.dropna(subset=['acceleration', 'change_in_direction'])\n",
    "\n",
    "# Round the values for better readability\n",
    "data_fe['acceleration'] = data_fe['acceleration'].round(4)\n",
    "data_fe['change_in_direction'] = data_fe['change_in_direction'].round(4)\n",
    "\n",
    "# Display the first few rows of the updated dataframe\n",
    "data_fe[['acceleration', 'change_in_direction']].head()\n",
    "data_fe.to_csv('H:/Study/IPCA/MIAA/MLA/TP2025/DataS1/jaguar_movement_data_cleaned.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112]\n"
     ]
    }
   ],
   "source": [
    "# Encode tag_local_identifier to numerical values\n",
    "\n",
    "data_fe['tag_local_identifier'] = pd.Categorical(data_fe['tag_local_identifier'])\n",
    "data_fe['tag_local_identifier'] = data_fe['tag_local_identifier'].cat.codes\n",
    "\n",
    "print(data_fe['tag_local_identifier'].unique())\n",
    "# data_encoded = pd.get_dummies(data_fe, columns=['tag_local_identifier'])\n",
    "# data_encoded.columns\n",
    "# data_encoded['tag_local_identifier'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now we want to get temporal features from Paraguay, Brazil, Costa Rica, Argentina and Mexico between 1/1/1999 and 31/12/2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version, please consider updating (latest version: 0.3.8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(553652, 127)\n",
      "(4169, 6)\n"
     ]
    }
   ],
   "source": [
    "# Get World  Climate data\n",
    "import kagglehub\n",
    "\n",
    "path = kagglehub.dataset_download(\"christopherlemke/monthly-climat-reports-from-stations-worldwide\")\n",
    "\n",
    "reports_data = pd.read_csv(path + '/dwd-cdc_CLIMAT_reports_stations_ww.csv')\n",
    "stations_data = pd.read_csv(path + '/dwd-cdc_station_data_ww.csv')\n",
    "\n",
    "# Save the data to a csv file\n",
    "reports_data.to_csv('H:/Study/IPCA/MIAA/MLA/TP2025/DataS1/monthly-climat-reports-from-stations-worldwide.csv', index=False)\n",
    "stations_data.to_csv('H:/Study/IPCA/MIAA/MLA/TP2025/DataS1/dwd-cdc_station_data_ww.csv', index=False)\n",
    "\n",
    "print(reports_data.shape)\n",
    "print(stations_data.shape)\n",
    "\n",
    "reports_data = reports_data.sample(SAMPLE_SIZE)\n",
    "# stations_data = stations_data.sample(SAMPLE_SIZE)\n",
    "\n",
    "# print(reports_data.head())\n",
    "# print(stations_data.head())\n",
    "\n",
    "# print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing Reports data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "def farenheit_to_celsius(farenheit):\n",
    "    return ((farenheit - 32) * 5.0)/9.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Integration of meteorological data such as temperature and rainfall. The temperature would be converted from Farenheit to Celsius, though the precipitation remains as mm.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "highest_daily_amount_precipitation_month_tenths_mm    6032\n",
      "mean_daily_maximum_air_temperature                       0\n",
      "mean_daily_minimum_air_temperature                       0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>station_id</th>\n",
       "      <th>G1</th>\n",
       "      <th>G1.1</th>\n",
       "      <th>G1.2</th>\n",
       "      <th>sn</th>\n",
       "      <th>monthly_mean_air_temperature</th>\n",
       "      <th>G1.3</th>\n",
       "      <th>sn.1</th>\n",
       "      <th>...</th>\n",
       "      <th>iw</th>\n",
       "      <th>fx</th>\n",
       "      <th>yfx</th>\n",
       "      <th>G4.6</th>\n",
       "      <th>Dts</th>\n",
       "      <th>Dgr</th>\n",
       "      <th>G4.7</th>\n",
       "      <th>iy</th>\n",
       "      <th>Gx</th>\n",
       "      <th>Gn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>174125</th>\n",
       "      <td>2010</td>\n",
       "      <td>5</td>\n",
       "      <td>7020</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42.78</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451173</th>\n",
       "      <td>2020</td>\n",
       "      <td>3</td>\n",
       "      <td>30844</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.78</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164920</th>\n",
       "      <td>2014</td>\n",
       "      <td>1</td>\n",
       "      <td>71261</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.22</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429291</th>\n",
       "      <td>2007</td>\n",
       "      <td>12</td>\n",
       "      <td>85289</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>136.11</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336933</th>\n",
       "      <td>2018</td>\n",
       "      <td>10</td>\n",
       "      <td>72514</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51.67</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 91 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        year  month  station_id   G1  G1.1  G1.2   sn  \\\n",
       "174125  2010      5        7020  1.0   2.0   3.0  0.0   \n",
       "451173  2020      3       30844  1.0   2.0   3.0  1.0   \n",
       "164920  2014      1       71261  1.0   2.0   3.0  1.0   \n",
       "429291  2007     12       85289  1.0   2.0   3.0  0.0   \n",
       "336933  2018     10       72514  1.0   2.0   3.0  0.0   \n",
       "\n",
       "        monthly_mean_air_temperature  G1.3  sn.1  ...   iw     fx   yfx  G4.6  \\\n",
       "174125                         42.78   4.0   0.0  ...  1.0  190.0  29.0   NaN   \n",
       "451173                         17.78   4.0   0.0  ...  NaN    NaN   NaN   NaN   \n",
       "164920                         27.22   4.0   1.0  ...  4.0   45.0   6.0   NaN   \n",
       "429291                        136.11   4.0   0.0  ...  4.0   18.0  11.0   NaN   \n",
       "336933                         51.67   4.0   0.0  ...  NaN    NaN   NaN   6.0   \n",
       "\n",
       "        Dts  Dgr  G4.7   iy    Gx    Gn  \n",
       "174125  NaN  NaN   7.0  2.0   6.0  18.0  \n",
       "451173  NaN  NaN   NaN  NaN   NaN   NaN  \n",
       "164920  NaN  NaN   NaN  NaN   NaN   NaN  \n",
       "429291  NaN  NaN   7.0  1.0  21.0  12.0  \n",
       "336933  1.0  0.0   NaN  NaN   NaN   NaN  \n",
       "\n",
       "[5 rows x 91 columns]"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove columns\n",
    "reports_data_dropped = reports_data.drop(['Po', 'Po.1', 'P', 'P.1', 'T.1', 'st', 'st.1', \n",
    "                                          'Tx.1', 'Tn.1', \n",
    "                                          'e', 'e.1', \n",
    "                                          'R1.1', 'nr.1', 'S1.1', 'Rd', 'mp', 'mT', 'mTx', 'mTn', 'me', 'mR', 'mS', \n",
    "                                            #   'sn', 'sn.1', 'sn.2', 'sn.3', 'sn.4', 'sn.5', 'sn.6', 'sn.7', 'sn.8', 'sn.9',\n",
    "                                            # 'G1', 'G1.1', 'G1.2', 'G1.3', 'G1.4', 'G1.5', 'G1.6', 'G1.7', 'G1.8',\n",
    "                                            # 'G2', 'G2.1', 'G2.2', 'G2.3', 'G2.4', 'G2.5', 'G2.6', 'G2.7', 'G2.8', 'G2.9',\n",
    "                                            # 'G3', 'G3.1', 'G3.2', 'G3.3', 'G3.4', 'G3.5', 'G3.6', 'G3.7', 'G3.8', 'G3.9',\n",
    "                                            # 'G4', 'G4.1', 'G4.2', 'G4.3', 'G4.4', 'G4.5', 'G4.6', 'G4.7',\n",
    "                                            'Yb', 'Yc', 'P', 'YP', 'YR', 'YS', 'YT', 'YTx',\n",
    "                                            'Ye', 'G4', 'Txd', 'yx', 'Tnd', 'Tax', 'Tan' ], axis=1)\n",
    "\n",
    "# Drop columns with no data\n",
    "reports_data_dropped = reports_data_dropped.dropna(axis=1, how='all')\n",
    "\n",
    "# Rename columns\n",
    "reports_data_renamed = reports_data_dropped.rename(columns={'IIiii':'station_id', 'T':'monthly_mean_air_temperature', \n",
    "                                            'Tx':'mean_daily_maximum_air_temperature', \n",
    "                                            'Tn':'mean_daily_minimum_air_temperature', \n",
    "                                            'R1':'total_precipitation_month', 'S1':'total_sunshine_month', \n",
    "                                            'ps':'percentage_total_sunshine_duration_relative_normal', \n",
    "                                            'P0':'monthly_mean_pressure_station_level', 'e':'mean_vapor_pressure_month', \n",
    "                                            'nr':'number_days_month_precipitation', \n",
    "                                            'yP':'missing_years_air_pressure', 'yR':'missing_years_precipitation', 'yS':'missing_years_sunshine_duration', \n",
    "                                            'yT':'missing_years_mean_air_temperature', 'yTx':'missing_years_mean_extreme_air_temperature', 'ye':'missing_years_vapor_pressure', \n",
    "                                            'T25':'days_month_maximum_air_temperature_25', 'T30':'days_month_maximum_air_temperature_30', \n",
    "                                            'T35':'days_month_maximum_air_temperature_35', 'T40':'days_month_maximum_air_temperature_40', \n",
    "                                            'Tn0':'days_month_minimum_air_temperature_0', 'Tx0':'days_month_maximum_air_temperature_0', 'R01':'days_month_precipitation_1', \n",
    "                                            'R05':'days_month_precipitation_5', 'R10':'days_month_precipitation_10', 'R50':'days_month_precipitation_50', \n",
    "                                            'R100':'days_month_precipitation_100', 'R150':'days_month_precipitation_150', 's00':'days_month_snow_depth_0', \n",
    "                                            's01':'days_month_snow_depth_1', 's10':'days_month_snow_depth_10', 's50':'days_month_snow_depth_50', 'f10':'days_month_wind_speed_10', \n",
    "                                            'f20':'days_month_wind_speed_20', 'f30':'days_month_wind_speed_30', 'V1':'days_month_visibility_50', 'V2':'days_month_visibility_100', \n",
    "                                            'V3':'days_month_visibility_1000', 'yn': 'day_lowest_daily_mean_air_temperature_month', 'yax': 'day_highest_daily_mean_air_temperature_month', 'yan':'day_lowest_air_tempreature_month',\n",
    "                                            'Rx':'highest_daily_amount_precipitation_month_tenths_mm',  \n",
    "                                            # 'yr':'day_highest_daily_amount_precipitation_month'\n",
    "                                            })\n",
    "\n",
    "# Remove rows with missing values in [year]\n",
    "reports_data_renamed = reports_data_renamed.dropna(subset=['year'])\n",
    "\n",
    "# Enconde Year, Month, and Station ID to integer\n",
    "reports_data_renamed['year'] = reports_data_renamed['year'].apply(lambda x: int(x) if pd.notnull(x) else x)\n",
    "reports_data_renamed['month'] = reports_data_renamed['month'].apply(lambda x: int(x) if pd.notnull(x) else x)\n",
    "reports_data_renamed['station_id'] = reports_data_renamed['station_id'].apply(lambda x: int(x) if pd.notnull(x) else x)\n",
    "reports_data_renamed['sn'] = reports_data_renamed['sn'].apply(lambda x: int(x) if pd.notnull(x) else x)\n",
    "\n",
    "# print(reports_data_renamed[['mean_daily_maximum_air_temperature']].head())\n",
    "\n",
    "# Convert temperature features to Celsius\n",
    "# °C = (°F - 32) × 5/9\n",
    "reports_data_renamed['monthly_mean_air_temperature'] = farenheit_to_celsius(reports_data_renamed['monthly_mean_air_temperature']).round(2)\n",
    "reports_data_renamed['mean_daily_maximum_air_temperature'] =  farenheit_to_celsius(reports_data_renamed['mean_daily_maximum_air_temperature']).round(2)\n",
    "reports_data_renamed['mean_daily_minimum_air_temperature'] = farenheit_to_celsius(reports_data_renamed['mean_daily_minimum_air_temperature']).round(2)\n",
    "\n",
    "# print(reports_data_renamed[['mean_daily_maximum_air_temperature']].head())\n",
    "\n",
    "# Check for missing values in temperature features\n",
    "# print(reports_data_renamed[['monthly_mean_air_temperature', 'mean_daily_maximum_air_temperature', 'mean_daily_minimum_air_temperature']].isnull().sum())\n",
    "\n",
    "# Fill missing values with the mean\n",
    "reports_data_renamed['monthly_mean_air_temperature'] = reports_data_renamed['monthly_mean_air_temperature'].fillna(reports_data_renamed['monthly_mean_air_temperature'].mean())\n",
    "reports_data_renamed['mean_daily_maximum_air_temperature'] = reports_data_renamed['mean_daily_maximum_air_temperature'].fillna(reports_data_renamed['mean_daily_maximum_air_temperature'].mean())\n",
    "reports_data_renamed['mean_daily_minimum_air_temperature'] = reports_data_renamed['mean_daily_minimum_air_temperature'].fillna(reports_data_renamed['mean_daily_minimum_air_temperature'].mean())\n",
    "\n",
    "print(reports_data_renamed[['highest_daily_amount_precipitation_month_tenths_mm', 'mean_daily_maximum_air_temperature', 'mean_daily_minimum_air_temperature']].isnull().sum())\n",
    "\n",
    "# Show null values\n",
    "# print(reports_data_renamed.isnull().sum())\n",
    "reports_data_renamed.to_csv('H:/Study/IPCA/MIAA/MLA/TP2025/DataS1/monthly-climat-reports-from-stations-worldwide-cleaned.csv', index=False)\n",
    "\n",
    "reports_data_renamed.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['01001' '01005' '01007' ... '99090' '99092' '99113']\n"
     ]
    }
   ],
   "source": [
    "# stations_data.dtypes\n",
    "\n",
    "# Rename columns\n",
    "# 0: Station ID, 1: Station Name, 2: Latitude, 3: Longitude, 4:Height, 5: Country\n",
    "stations_data_renamed = stations_data.rename(columns={'0':'station_id', '1':'station_name', '2':'latitude', '3':'longitude', '4':'height', '5':'country'})\n",
    "stations_data_renamed['station_id'] = stations_data_renamed['station_id'].str.strip()\n",
    "stations_data_renamed = stations_data_renamed[:-1]\n",
    "\n",
    "print(stations_data_renamed['station_id'].unique())\n",
    "\n",
    "\n",
    "stations_data_renamed['station_id'] = (\n",
    "    stations_data_renamed['station_id']\n",
    "    .str.replace(r'\\D', '', regex=True)  # Remove all non-digit characters\n",
    "    .pipe(pd.to_numeric, errors='coerce')  # Convert to numeric, invalid become NaN\n",
    "    .astype('Int64')  # Convert to pandas' nullable Int64 type\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         26.0\n",
      "1          NaN\n",
      "2        158.0\n",
      "3        967.0\n",
      "4        284.0\n",
      "         ...  \n",
      "18716      NaN\n",
      "18717      1.0\n",
      "18718    144.0\n",
      "18719     74.0\n",
      "18720    325.0\n",
      "Name: highest_daily_amount_precipitation_month_tenths_mm, Length: 18721, dtype: float64\n",
      "=== REPORTS DATA ===\n",
      "        year  month  station_id   G1  G1.1  G1.2   sn  \\\n",
      "174125  2010      5        7020  1.0   2.0   3.0  0.0   \n",
      "451173  2020      3       30844  1.0   2.0   3.0  1.0   \n",
      "164920  2014      1       71261  1.0   2.0   3.0  1.0   \n",
      "429291  2007     12       85289  1.0   2.0   3.0  0.0   \n",
      "336933  2018     10       72514  1.0   2.0   3.0  0.0   \n",
      "\n",
      "        monthly_mean_air_temperature  G1.3  sn.1  ...   iw     fx   yfx  G4.6  \\\n",
      "174125                         42.78   4.0   0.0  ...  1.0  190.0  29.0   NaN   \n",
      "451173                         17.78   4.0   0.0  ...  NaN    NaN   NaN   NaN   \n",
      "164920                         27.22   4.0   1.0  ...  4.0   45.0   6.0   NaN   \n",
      "429291                        136.11   4.0   0.0  ...  4.0   18.0  11.0   NaN   \n",
      "336933                         51.67   4.0   0.0  ...  NaN    NaN   NaN   6.0   \n",
      "\n",
      "        Dts  Dgr  G4.7   iy    Gx    Gn  \n",
      "174125  NaN  NaN   7.0  2.0   6.0  18.0  \n",
      "451173  NaN  NaN   NaN  NaN   NaN   NaN  \n",
      "164920  NaN  NaN   NaN  NaN   NaN   NaN  \n",
      "429291  NaN  NaN   7.0  1.0  21.0  12.0  \n",
      "336933  1.0  0.0   NaN  NaN   NaN   NaN  \n",
      "\n",
      "[5 rows x 91 columns]\n",
      "=== STATIONS DATA ===\n",
      "   station_id              station_name  \\\n",
      "0        1001                 Jan Mayen   \n",
      "1        1005             Isfjord Radio   \n",
      "2        1007                Ny-Alesund   \n",
      "3        1008                  Svalbard   \n",
      "4        1025            Tromso/Langnes   \n",
      "\n",
      "                                      latitude   longitude   height  \\\n",
      "0                                        70.94      -08.67        9   \n",
      "1                                        78.06       13.63        9   \n",
      "2                                        78.92       11.93        8   \n",
      "3                                        78.25       15.50       27   \n",
      "4                                        69.68       18.91        9   \n",
      "\n",
      "                                             country  \n",
      "0   Norway                                       ...  \n",
      "1   Norway                                       ...  \n",
      "2   Norway                                       ...  \n",
      "3   Norway                                       ...  \n",
      "4   Norway                                       ...  \n",
      "=== DATA FE ===\n",
      "                             event_id           timestamp  location_long  \\\n",
      "tag_local_identifier                                                       \n",
      "35957                131873  131874.0 2015-10-12 03:00:00     -57.503302   \n",
      "                     131874  131875.0 2015-10-12 04:00:00     -57.503297   \n",
      "                     131875  131876.0 2015-10-12 05:00:00     -57.503258   \n",
      "                     131876  131877.0 2015-10-12 06:00:00     -57.502844   \n",
      "                     131877  131878.0 2015-10-12 07:00:00     -57.502828   \n",
      "\n",
      "                             location_lat individual_taxon_canonical_name  \\\n",
      "tag_local_identifier                                                        \n",
      "35957                131873    -16.881220                   Panthera onca   \n",
      "                     131874    -16.881144                   Panthera onca   \n",
      "                     131875    -16.881164                   Panthera onca   \n",
      "                     131876    -16.880861                   Panthera onca   \n",
      "                     131877    -16.880876                   Panthera onca   \n",
      "\n",
      "                             tag_local_identifier  \\\n",
      "tag_local_identifier                                \n",
      "35957                131873                     0   \n",
      "                     131874                     0   \n",
      "                     131875                     0   \n",
      "                     131876                     0   \n",
      "                     131877                     0   \n",
      "\n",
      "                             individual_local_identifier_ID     study_name  \\\n",
      "tag_local_identifier                                                         \n",
      "35957                131873                             117  Jaguar_Taiama   \n",
      "                     131874                             117  Jaguar_Taiama   \n",
      "                     131875                             117  Jaguar_Taiama   \n",
      "                     131876                             117  Jaguar_Taiama   \n",
      "                     131877                             117  Jaguar_Taiama   \n",
      "\n",
      "                            country  hour  ...  year  dayofweek        date  \\\n",
      "tag_local_identifier                       ...                                \n",
      "35957                131873  Brazil     3  ...  2015          0  2015-10-12   \n",
      "                     131874  Brazil     4  ...  2015          0  2015-10-12   \n",
      "                     131875  Brazil     5  ...  2015          0  2015-10-12   \n",
      "                     131876  Brazil     6  ...  2015          0  2015-10-12   \n",
      "                     131877  Brazil     7  ...  2015          0  2015-10-12   \n",
      "\n",
      "                             distance time_diff  velocity  movement  \\\n",
      "tag_local_identifier                                                  \n",
      "35957                131873    0.0026  0.983333      0.00   resting   \n",
      "                     131874    0.0084  1.000000      0.01   resting   \n",
      "                     131875    0.0047  1.000000      0.00   resting   \n",
      "                     131876    0.0554  1.000000      0.06   resting   \n",
      "                     131877    0.0023  1.000000      0.00   resting   \n",
      "\n",
      "                             direction acceleration  change_in_direction  \n",
      "tag_local_identifier                                                      \n",
      "35957                131873   1.716691      -0.0102               1.4025  \n",
      "                     131874   0.065868       0.0100              -1.6508  \n",
      "                     131875   2.031370      -0.0100               1.9655  \n",
      "                     131876   0.940825       0.0600              -1.0905  \n",
      "                     131877   2.309870      -0.0600               1.3690  \n",
      "\n",
      "[5 rows x 22 columns]\n",
      "Data successfully loaded into SQLite database!\n",
      "=== DATA MERGED ===\n",
      "   year  month  station_id   G1  G1.1  G1.2   sn  \\\n",
      "0  2010      5        7020  1.0   2.0   3.0  0.0   \n",
      "1  2020      3       30844  1.0   2.0   3.0  1.0   \n",
      "2  2014      1       71261  1.0   2.0   3.0  1.0   \n",
      "3  2007     12       85289  1.0   2.0   3.0  0.0   \n",
      "4  2018     10       72514  1.0   2.0   3.0  0.0   \n",
      "\n",
      "   monthly_mean_air_temperature  G1.3  sn.1  ...  Dgr  G4.7   iy    Gx    Gn  \\\n",
      "0                         42.78   4.0   0.0  ...  NaN   7.0  2.0   6.0  18.0   \n",
      "1                         17.78   4.0   0.0  ...  NaN   NaN  NaN   NaN   NaN   \n",
      "2                         27.22   4.0   1.0  ...  NaN   NaN  NaN   NaN   NaN   \n",
      "3                        136.11   4.0   0.0  ...  NaN   7.0  1.0  21.0  12.0   \n",
      "4                         51.67   4.0   0.0  ...  0.0   NaN  NaN   NaN   NaN   \n",
      "\n",
      "                      station_name  \\\n",
      "0                  Cap de la Hague   \n",
      "1                            Hilok   \n",
      "2                     Goderich/ONT   \n",
      "3                    Puerto Suarez   \n",
      "4            Williamsport Airp./PA   \n",
      "\n",
      "                                         latitude   longitude   height  \\\n",
      "0                                           49.72      -01.94        8   \n",
      "1                                           51.37      110.47      802   \n",
      "2                                           43.76      -81.71      214   \n",
      "3                                          -18.98      -57.82      135   \n",
      "4                                           41.24      -76.92      160   \n",
      "\n",
      "                                             country  \n",
      "0   France                                       ...  \n",
      "1   Russian Federation                           ...  \n",
      "2   Canada                                       ...  \n",
      "3   Bolivia                                      ...  \n",
      "4   United States of America                     ...  \n",
      "\n",
      "[5 rows x 96 columns]\n",
      "Database connection closed.\n",
      "=== DATA MERGED COUNTRIES ===\n",
      "   event_id           timestamp  location_long  location_lat  \\\n",
      "0  132328.0 2015-11-01 00:00:00     -57.434359    -16.930896   \n",
      "1  132329.0 2015-11-01 01:00:00     -57.434359    -16.931034   \n",
      "2  132330.0 2015-11-01 03:00:00     -57.434360    -16.930949   \n",
      "3  132331.0 2015-11-01 04:00:00     -57.434446    -16.930911   \n",
      "4  132332.0 2015-11-01 05:00:00     -57.434407    -16.930931   \n",
      "\n",
      "  individual_taxon_canonical_name  tag_local_identifier  \\\n",
      "0                   Panthera onca                     0   \n",
      "1                   Panthera onca                     0   \n",
      "2                   Panthera onca                     0   \n",
      "3                   Panthera onca                     0   \n",
      "4                   Panthera onca                     0   \n",
      "\n",
      "   individual_local_identifier_ID     study_name country  hour  ...  velocity  \\\n",
      "0                             117  Jaguar_Taiama  Brazil     0  ...      0.01   \n",
      "1                             117  Jaguar_Taiama  Brazil     1  ...      0.02   \n",
      "2                             117  Jaguar_Taiama  Brazil     3  ...      0.00   \n",
      "3                             117  Jaguar_Taiama  Brazil     4  ...      0.01   \n",
      "4                             117  Jaguar_Taiama  Brazil     5  ...      0.00   \n",
      "\n",
      "   movement  direction  acceleration change_in_direction  \\\n",
      "0   resting   0.999533          0.00              0.2405   \n",
      "1   resting   3.137229          0.01              2.1377   \n",
      "2   resting  -0.012986         -0.01             -3.1502   \n",
      "3   resting  -1.161304          0.01             -1.1483   \n",
      "4   resting   2.030354         -0.01              3.1917   \n",
      "\n",
      "   mean_daily_maximum_air_temperature  mean_daily_minimum_air_temperature  \\\n",
      "0                             189.445                               117.5   \n",
      "1                             189.445                               117.5   \n",
      "2                             189.445                               117.5   \n",
      "3                             189.445                               117.5   \n",
      "4                             189.445                               117.5   \n",
      "\n",
      "   total_precipitation_month  \\\n",
      "0                    10014.0   \n",
      "1                    10014.0   \n",
      "2                    10014.0   \n",
      "3                    10014.0   \n",
      "4                    10014.0   \n",
      "\n",
      "  highest_daily_amount_precipitation_month_tenths_mm  \\\n",
      "0                                               74.0   \n",
      "1                                               74.0   \n",
      "2                                               74.0   \n",
      "3                                               74.0   \n",
      "4                                               74.0   \n",
      "\n",
      "   number_days_month_precipitation  \n",
      "0                              1.0  \n",
      "1                              1.0  \n",
      "2                              1.0  \n",
      "3                              1.0  \n",
      "4                              1.0  \n",
      "\n",
      "[5 rows x 27 columns]\n"
     ]
    }
   ],
   "source": [
    "# Merge the reports and stations data by station_id\n",
    "import sqlite3\n",
    "\n",
    "data_merged = pd.merge(reports_data_renamed, stations_data_renamed, on='station_id')\n",
    "\n",
    "# data_fe['country'].unique()\n",
    "\n",
    "print(data_merged['highest_daily_amount_precipitation_month_tenths_mm'])\n",
    "\n",
    "data_merged['country'] = data_merged['country'].str.strip()\n",
    "# print(data_merged.columns)\n",
    "\n",
    "# print(data_merged['country'].unique())\n",
    "\n",
    "# data_merged['country'].isnull().sum()\n",
    "\n",
    "# print(data_merged.columns)\n",
    "\n",
    "month_daily_data = data_merged[['year', 'month', 'station_id', 'country', 'mean_daily_maximum_air_temperature', 'mean_daily_minimum_air_temperature', 'total_precipitation_month', \n",
    "'number_days_month_precipitation', 'total_sunshine_month', 'percentage_total_sunshine_duration_relative_normal', 'days_month_maximum_air_temperature_25', \n",
    "'days_month_maximum_air_temperature_30', 'days_month_maximum_air_temperature_35', 'days_month_maximum_air_temperature_40', 'days_month_minimum_air_temperature_0', \n",
    "'days_month_maximum_air_temperature_0', 'days_month_precipitation_1', 'days_month_precipitation_5', 'days_month_precipitation_10', 'days_month_precipitation_50', \n",
    "'days_month_precipitation_100', 'days_month_precipitation_150', 'days_month_snow_depth_0', 'days_month_snow_depth_1', 'days_month_snow_depth_10', 'days_month_snow_depth_50', \n",
    "'days_month_visibility_50', 'days_month_visibility_100', 'days_month_visibility_1000', 'day_lowest_air_tempreature_month', 'day_highest_daily_mean_air_temperature_month', 'day_lowest_air_tempreature_month', \n",
    "'highest_daily_amount_precipitation_month_tenths_mm']]\n",
    "\n",
    "# print(data_fe.shape)\n",
    "\n",
    "# print(month_daily_data.head())\n",
    "\n",
    "# data_merged.head()\n",
    "\n",
    "conn = sqlite3.connect('jaguar_data.db')\n",
    "\n",
    "# Save data to SQLite database\n",
    "reports_data_renamed.to_sql('reports', conn, if_exists='replace', index=False)\n",
    "stations_data_renamed.to_sql('stations', conn, if_exists='replace', index=False)\n",
    "# data_merged.to_sql('reports_country', conn, if_exists='replace', index=False)\n",
    "data_fe.to_sql('data_fe', conn, if_exists='replace', index=False)\n",
    "\n",
    "print(\"=== REPORTS DATA ===\")\n",
    "print(reports_data_renamed.head())\n",
    "\n",
    "print(\"=== STATIONS DATA ===\")\n",
    "print(stations_data_renamed.head())\n",
    "\n",
    "print(\"=== DATA FE ===\")\n",
    "print(data_fe.head())\n",
    "\n",
    "print(\"Data successfully loaded into SQLite database!\")\n",
    "\n",
    "conn.close()\n",
    "\n",
    "# Merge data_merged with data_fe only by the countries and date in data_fe\n",
    "# data_merged_countries = pd.merge(data_fe, month_daily_data, on=['country', 'year', 'month'], how='inner')\n",
    "\n",
    "# data_merged_countries = pd.merge(data_merged, data_fe, on='country', how='inner')\n",
    "# data_merged_countries = data_merged[data_merged['country'].isin(data_fe['country'].unique())]\n",
    "# data_merged_countries.head()\n",
    "\n",
    "# print(reports_data_renamed['highest_daily_amount_precipitation_month_tenths_mm'])\n",
    "\n",
    "# 1. Merge reports and stations\n",
    "data_merged = pd.merge(\n",
    "    reports_data_renamed,\n",
    "    stations_data_renamed,\n",
    "    on='station_id'\n",
    ")\n",
    "\n",
    "print(\"=== DATA MERGED ===\")\n",
    "print(data_merged.head())\n",
    "\n",
    "# print(data_merged['highest_daily_amount_precipitation_month_tenths_mm'])\n",
    "\n",
    "# 2. Clean and rename columns\n",
    "data_merged['country'] = data_merged['country'].str.strip()\n",
    "data_merged = data_merged.rename(columns={\n",
    "    'year_x': 'year',\n",
    "    'month_x': 'month'\n",
    "})\n",
    "\n",
    "# 3. Aggregate to country-month level\n",
    "country_month_climate = (\n",
    "    data_merged\n",
    "    .groupby(['country', 'year', 'month'])\n",
    "    .agg({\n",
    "        'mean_daily_maximum_air_temperature': 'mean',\n",
    "        'mean_daily_minimum_air_temperature': 'mean',\n",
    "        'total_precipitation_month': 'sum',\n",
    "        'highest_daily_amount_precipitation_month_tenths_mm': 'mean',\n",
    "        'number_days_month_precipitation': 'max'\n",
    "    })\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "data_fe = data_fe.rename(columns={\n",
    "    'year_x': 'year',\n",
    "    'month_x': 'month'\n",
    "})\n",
    "\n",
    "# 4. Merge with movement data\n",
    "data_merged_countries = pd.merge(\n",
    "    data_fe,\n",
    "    country_month_climate,\n",
    "    on=['country', 'year', 'month'],\n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "print(\"Database connection closed.\")\n",
    "\n",
    "print(\"=== DATA MERGED COUNTRIES ===\")\n",
    "print(data_merged_countries.head())\n",
    "\n",
    "# Save\n",
    "data_merged_countries.to_csv('H:/Study/IPCA/MIAA/MLA/TP2025/DataS1/jaguar_movement_with_countries_climate_data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
