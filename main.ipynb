{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from geopy.distance import geodesic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lmars\\AppData\\Local\\Temp\\ipykernel_16208\\833975228.py:2: DtypeWarning: Columns (5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv('DataS1/jaguar_movement_data.csv')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Event_ID</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>location.long</th>\n",
       "      <th>location.lat</th>\n",
       "      <th>individual.taxon.canonical.name</th>\n",
       "      <th>tag.local.identifier</th>\n",
       "      <th>individual.local.identifier (ID)</th>\n",
       "      <th>study.name</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>6/15/10 22:43</td>\n",
       "      <td>-58.030128</td>\n",
       "      <td>-23.326947</td>\n",
       "      <td>Panthera onca</td>\n",
       "      <td>0-333005</td>\n",
       "      <td>1</td>\n",
       "      <td>Humid Chaco</td>\n",
       "      <td>Paraguay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>6/16/10 2:52</td>\n",
       "      <td>-58.030643</td>\n",
       "      <td>-23.328427</td>\n",
       "      <td>Panthera onca</td>\n",
       "      <td>0-333005</td>\n",
       "      <td>1</td>\n",
       "      <td>Humid Chaco</td>\n",
       "      <td>Paraguay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>6/16/10 22:36</td>\n",
       "      <td>-58.030472</td>\n",
       "      <td>-23.327311</td>\n",
       "      <td>Panthera onca</td>\n",
       "      <td>0-333005</td>\n",
       "      <td>1</td>\n",
       "      <td>Humid Chaco</td>\n",
       "      <td>Paraguay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>6/17/10 16:42</td>\n",
       "      <td>-58.027983</td>\n",
       "      <td>-23.309952</td>\n",
       "      <td>Panthera onca</td>\n",
       "      <td>0-333005</td>\n",
       "      <td>1</td>\n",
       "      <td>Humid Chaco</td>\n",
       "      <td>Paraguay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>6/17/10 20:37</td>\n",
       "      <td>-58.027747</td>\n",
       "      <td>-23.310006</td>\n",
       "      <td>Panthera onca</td>\n",
       "      <td>0-333005</td>\n",
       "      <td>1</td>\n",
       "      <td>Humid Chaco</td>\n",
       "      <td>Paraguay</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Event_ID      timestamp  location.long  location.lat  \\\n",
       "0       1.0  6/15/10 22:43     -58.030128    -23.326947   \n",
       "1       2.0   6/16/10 2:52     -58.030643    -23.328427   \n",
       "2       3.0  6/16/10 22:36     -58.030472    -23.327311   \n",
       "3       4.0  6/17/10 16:42     -58.027983    -23.309952   \n",
       "4       5.0  6/17/10 20:37     -58.027747    -23.310006   \n",
       "\n",
       "  individual.taxon.canonical.name tag.local.identifier  \\\n",
       "0                   Panthera onca             0-333005   \n",
       "1                   Panthera onca             0-333005   \n",
       "2                   Panthera onca             0-333005   \n",
       "3                   Panthera onca             0-333005   \n",
       "4                   Panthera onca             0-333005   \n",
       "\n",
       "   individual.local.identifier (ID)   study.name   country  \n",
       "0                                 1  Humid Chaco  Paraguay  \n",
       "1                                 1  Humid Chaco  Paraguay  \n",
       "2                                 1  Humid Chaco  Paraguay  \n",
       "3                                 1  Humid Chaco  Paraguay  \n",
       "4                                 1  Humid Chaco  Paraguay  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load dataset\n",
    "data = pd.read_csv('DataS1/jaguar_movement_data.csv')\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Event_ID                            0\n",
       "timestamp                           0\n",
       "location.long                       0\n",
       "location.lat                        0\n",
       "individual.taxon.canonical.name     0\n",
       "tag.local.identifier                0\n",
       "individual.local.identifier (ID)    0\n",
       "study.name                          0\n",
       "country                             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_cp = data.copy()\n",
    "data_cp.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fixing features names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['event_id', 'timestamp', 'location_long', 'location_lat',\n",
       "       'individual_taxon_canonical_name', 'tag_local_identifier',\n",
       "       'individual_local_identifier_ID', 'study_name', 'country'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fix features names Event_ID,timestamp,location.long,location.lat,individual.taxon.canonical.name,tag.local.identifier,individual.local.identifier (ID),study.name,country\n",
    "data_cp = data_cp.rename(columns={'Event_ID':'event_id','timestamp':'timestamp','location.long':'location_long','location.lat':'location_lat','individual.taxon.canonical.name':'individual_taxon_canonical_name','tag.local.identifier':'tag_local_identifier','individual.local.identifier (ID)':'individual_local_identifier_ID','study.name':'study_name','country':'country'})\n",
    "\n",
    "# Print features names\n",
    "data_cp.columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lmars\\AppData\\Local\\Temp\\ipykernel_16208\\3021486648.py:2: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  data_cp['timestamp'] = pd.to_datetime(data_cp['timestamp'])\n"
     ]
    }
   ],
   "source": [
    "# Parsing the timestamp column into a datetime format\n",
    "data_cp['timestamp'] = pd.to_datetime(data_cp['timestamp'])\n",
    "\n",
    "# Extract time of day, day of the week, month, etc., for temporal features.\n",
    "data_cp['hour'] = data_cp['timestamp'].dt.hour\n",
    "data_cp['day'] = data_cp['timestamp'].dt.day\n",
    "data_cp['month'] = data_cp['timestamp'].dt.month\n",
    "data_cp['year'] = data_cp['timestamp'].dt.year\n",
    "data_cp['dayofweek'] = data_cp['timestamp'].dt.dayofweek\n",
    "data_cp['date'] = data_cp['timestamp'].dt.date\n",
    "\n",
    "# Show unique values for day, month and year\n",
    "# print(data_cp['day'].unique())\n",
    "# print(data_cp['month'].unique())\n",
    "# print(data_cp['year'].unique())\n",
    "# print(data_cp['country'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['event_id', 'timestamp', 'location_long', 'location_lat',\n",
       "       'individual_taxon_canonical_name', 'tag_local_identifier',\n",
       "       'individual_local_identifier_ID', 'study_name', 'country', 'hour',\n",
       "       'day', 'month', 'year', 'dayofweek', 'date'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data_cp = data_cp.drop(['event_id', 'individual_local_identifier_ID', 'tag_local_identifier'], axis=1)\n",
    "\n",
    "data_cp.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Geospatial Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating distances between consecutive events.\n",
    "### Calculating the distance between points using the Haversine Formula and group the data by tag_local_identifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>event_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>location_long</th>\n",
       "      <th>location_lat</th>\n",
       "      <th>individual_taxon_canonical_name</th>\n",
       "      <th>tag_local_identifier</th>\n",
       "      <th>individual_local_identifier_ID</th>\n",
       "      <th>study_name</th>\n",
       "      <th>country</th>\n",
       "      <th>hour</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>date</th>\n",
       "      <th>distance</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tag_local_identifier</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">35957</th>\n",
       "      <th>131870</th>\n",
       "      <td>131871.0</td>\n",
       "      <td>2015-10-12 00:00:00</td>\n",
       "      <td>-57.503400</td>\n",
       "      <td>-16.881275</td>\n",
       "      <td>Panthera onca</td>\n",
       "      <td>35957</td>\n",
       "      <td>117</td>\n",
       "      <td>Jaguar_Taiama</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>2015</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-10-12</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131871</th>\n",
       "      <td>131872.0</td>\n",
       "      <td>2015-10-12 01:00:00</td>\n",
       "      <td>-57.503355</td>\n",
       "      <td>-16.881304</td>\n",
       "      <td>Panthera onca</td>\n",
       "      <td>35957</td>\n",
       "      <td>117</td>\n",
       "      <td>Jaguar_Taiama</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>2015</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-10-12</td>\n",
       "      <td>0.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131872</th>\n",
       "      <td>131873.0</td>\n",
       "      <td>2015-10-12 02:01:00</td>\n",
       "      <td>-57.503327</td>\n",
       "      <td>-16.881216</td>\n",
       "      <td>Panthera onca</td>\n",
       "      <td>35957</td>\n",
       "      <td>117</td>\n",
       "      <td>Jaguar_Taiama</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>2015</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-10-12</td>\n",
       "      <td>0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131873</th>\n",
       "      <td>131874.0</td>\n",
       "      <td>2015-10-12 03:00:00</td>\n",
       "      <td>-57.503302</td>\n",
       "      <td>-16.881220</td>\n",
       "      <td>Panthera onca</td>\n",
       "      <td>35957</td>\n",
       "      <td>117</td>\n",
       "      <td>Jaguar_Taiama</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>2015</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-10-12</td>\n",
       "      <td>0.003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131874</th>\n",
       "      <td>131875.0</td>\n",
       "      <td>2015-10-12 04:00:00</td>\n",
       "      <td>-57.503297</td>\n",
       "      <td>-16.881144</td>\n",
       "      <td>Panthera onca</td>\n",
       "      <td>35957</td>\n",
       "      <td>117</td>\n",
       "      <td>Jaguar_Taiama</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>2015</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-10-12</td>\n",
       "      <td>0.008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             event_id           timestamp  location_long  \\\n",
       "tag_local_identifier                                                       \n",
       "35957                131870  131871.0 2015-10-12 00:00:00     -57.503400   \n",
       "                     131871  131872.0 2015-10-12 01:00:00     -57.503355   \n",
       "                     131872  131873.0 2015-10-12 02:01:00     -57.503327   \n",
       "                     131873  131874.0 2015-10-12 03:00:00     -57.503302   \n",
       "                     131874  131875.0 2015-10-12 04:00:00     -57.503297   \n",
       "\n",
       "                             location_lat individual_taxon_canonical_name  \\\n",
       "tag_local_identifier                                                        \n",
       "35957                131870    -16.881275                   Panthera onca   \n",
       "                     131871    -16.881304                   Panthera onca   \n",
       "                     131872    -16.881216                   Panthera onca   \n",
       "                     131873    -16.881220                   Panthera onca   \n",
       "                     131874    -16.881144                   Panthera onca   \n",
       "\n",
       "                            tag_local_identifier  \\\n",
       "tag_local_identifier                               \n",
       "35957                131870                35957   \n",
       "                     131871                35957   \n",
       "                     131872                35957   \n",
       "                     131873                35957   \n",
       "                     131874                35957   \n",
       "\n",
       "                             individual_local_identifier_ID     study_name  \\\n",
       "tag_local_identifier                                                         \n",
       "35957                131870                             117  Jaguar_Taiama   \n",
       "                     131871                             117  Jaguar_Taiama   \n",
       "                     131872                             117  Jaguar_Taiama   \n",
       "                     131873                             117  Jaguar_Taiama   \n",
       "                     131874                             117  Jaguar_Taiama   \n",
       "\n",
       "                            country  hour  day  month  year  dayofweek  \\\n",
       "tag_local_identifier                                                     \n",
       "35957                131870  Brazil     0   12     10  2015          0   \n",
       "                     131871  Brazil     1   12     10  2015          0   \n",
       "                     131872  Brazil     2   12     10  2015          0   \n",
       "                     131873  Brazil     3   12     10  2015          0   \n",
       "                     131874  Brazil     4   12     10  2015          0   \n",
       "\n",
       "                                   date  distance  \n",
       "tag_local_identifier                               \n",
       "35957                131870  2015-10-12       NaN  \n",
       "                     131871  2015-10-12     0.006  \n",
       "                     131872  2015-10-12     0.010  \n",
       "                     131873  2015-10-12     0.003  \n",
       "                     131874  2015-10-12     0.008  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_fe = data_cp.copy()\n",
    "\n",
    "data_fe['timestamp'] = pd.to_datetime(data_fe['timestamp'])\n",
    "\n",
    "# Define Haversine formula for distance calculation\n",
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    R = 6371000\n",
    "    phi1 = np.radians(lat1)\n",
    "    phi2 = np.radians(lat2)\n",
    "    delta_phi = np.radians(lat2 - lat1)\n",
    "    delta_lambda = np.radians(lon2 - lon1)\n",
    "\n",
    "    a = np.sin(delta_phi / 2)**2 + np.cos(phi1) * np.cos(phi2) * np.sin(delta_lambda / 2)**2\n",
    "    c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1 - a))\n",
    "\n",
    "    return R * c\n",
    "\n",
    "# Function to calculate distance only for the same animal\n",
    "def calculate_distances_for_animal(group):\n",
    "    group = group.sort_values('timestamp')\n",
    "    group['distance'] = haversine(\n",
    "        group['location_lat'].shift(),\n",
    "        group['location_long'].shift(),\n",
    "        group['location_lat'],\n",
    "        group['location_long']\n",
    "    )\n",
    "    return group\n",
    "\n",
    "data_fe = data_fe.groupby('tag_local_identifier').apply(calculate_distances_for_animal)\n",
    "\n",
    "# Convert distance to kilometers\n",
    "data_fe['distance'] = data_fe['distance'] / 1000\n",
    "data_fe['distance'] = data_fe['distance'].round(3)\n",
    "\n",
    "data_fe.head()\n",
    "# data_fe.to_csv('DataS1/jaguar_movement_data_cleaned.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating velocity, direction, and movement features based on location data (location.long, location.lat)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tag_local_identifier        \n",
      "35957                 131870         NaN\n",
      "                      131871    1.000000\n",
      "                      131872    1.016667\n",
      "                      131873    0.983333\n",
      "                      131874    1.000000\n",
      "Name: time_diff, dtype: float64\n",
      "                             distance  time_diff  velocity\n",
      "tag_local_identifier                                      \n",
      "35957                131871       6.0   1.000000    0.0017\n",
      "                     131872      10.0   1.016667    0.0027\n",
      "                     131873       3.0   0.983333    0.0008\n",
      "                     131874       8.0   1.000000    0.0022\n",
      "                     131875       5.0   1.000000    0.0014\n"
     ]
    }
   ],
   "source": [
    "# Creating velocity, direction, and movement features based on location data (location.long, location.lat).\n",
    "# time_diff = (data_cp['timestamp'] - data_cp['timestamp'].shift()).dt.total_seconds()\n",
    "\n",
    "# Ensuring the distance is in meters and the time differece is in seconds\n",
    "time_diff = data_fe['time_diff'] = data_fe['timestamp'].diff().dt.total_seconds() / 3600\n",
    "\n",
    "data_fe['distance'] = data_fe['distance'] * 1000\n",
    "time_diff_seconds = data_fe['time_diff'] * 3600\n",
    "\n",
    "print(data_fe['time_diff'].head())\n",
    "\n",
    "data_fe['velocity'] = data_fe['distance'] / time_diff_seconds\n",
    "data_fe['velocity'] = data_fe['velocity'].round(4)\n",
    "data_fe = data_fe.dropna(subset=[ 'distance', 'velocity'])\n",
    "\n",
    "data_fe['direction'] = np.arctan2(data_fe['location_long'] - data_fe['location_long'].shift(), data_fe['location_lat'] - data_fe['location_lat'].shift())\n",
    "data_fe['movement'] = np.where(data_fe['velocity'] > 0, 'moving', 'not_moving')\n",
    "\n",
    "# data_cp = data_cp.dropna()\n",
    "print(data_fe[['distance', 'time_diff', 'velocity']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Derive acceleration or changes in movement direction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>acceleration</th>\n",
       "      <th>change_in_direction</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tag_local_identifier</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">35957</th>\n",
       "      <th>131873</th>\n",
       "      <td>-0.0019</td>\n",
       "      <td>1.4025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131874</th>\n",
       "      <td>0.0014</td>\n",
       "      <td>-1.6508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131875</th>\n",
       "      <td>-0.0008</td>\n",
       "      <td>1.9655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131876</th>\n",
       "      <td>0.0139</td>\n",
       "      <td>-1.0905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131877</th>\n",
       "      <td>-0.0147</td>\n",
       "      <td>1.3690</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             acceleration  change_in_direction\n",
       "tag_local_identifier                                          \n",
       "35957                131873       -0.0019               1.4025\n",
       "                     131874        0.0014              -1.6508\n",
       "                     131875       -0.0008               1.9655\n",
       "                     131876        0.0139              -1.0905\n",
       "                     131877       -0.0147               1.3690"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate acceleration as the change in velocity over time\n",
    "data_fe['acceleration'] = data_fe['velocity'].diff() / data_fe['time_diff']\n",
    "\n",
    "# Calculate change in direction\n",
    "data_fe['change_in_direction'] = data_fe['direction'].diff()\n",
    "\n",
    "# Drop rows with NaN values in acceleration and change_in_direction\n",
    "data_fe = data_fe.dropna(subset=['acceleration', 'change_in_direction'])\n",
    "\n",
    "# Round the values for better readability\n",
    "data_fe['acceleration'] = data_fe['acceleration'].round(4)\n",
    "data_fe['change_in_direction'] = data_fe['change_in_direction'].round(4)\n",
    "\n",
    "# Display the first few rows of the updated dataframe\n",
    "data_fe[['acceleration', 'change_in_direction']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encode Categorical Variables\n",
    "# data_encoded = pd.get_dummies(data_fe, columns=['individual_taxon_canonical_name', 'study_name', 'country', 'movement'])\n",
    "# data_encoded.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now we want to get temporal features from Paraguay, Brazil, Costa Rica, Argentina and Mexico between 1/1/1999 and 31/12/2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.5), please consider upgrading to the latest version (0.3.6).\n"
     ]
    }
   ],
   "source": [
    "# Get World  Climate data\n",
    "import kagglehub\n",
    "\n",
    "path = kagglehub.dataset_download(\"christopherlemke/monthly-climat-reports-from-stations-worldwide\")\n",
    "\n",
    "reports_data = pd.read_csv(path + '/dwd-cdc_CLIMAT_reports_stations_ww.csv')\n",
    "stations_data = pd.read_csv(path + '/dwd-cdc_station_data_ww.csv')\n",
    "\n",
    "# Save the data to a csv file\n",
    "reports_data.to_csv('DataS1/monthly-climat-reports-from-stations-worldwide.csv', index=False)\n",
    "stations_data.to_csv('DataS1/dwd-cdc_station_data_ww.csv', index=False)\n",
    "\n",
    "# print(reports_data.head())\n",
    "# print(stations_data.head())\n",
    "\n",
    "# print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing Reports data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "year               0\n",
      "month              0\n",
      "station_id         0\n",
      "G1             47554\n",
      "G1.1           38840\n",
      "               ...  \n",
      "Dgr           281442\n",
      "G4.7          365352\n",
      "iy            366752\n",
      "Gx            366044\n",
      "Gn            366069\n",
      "Length: 91, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>station_id</th>\n",
       "      <th>G1</th>\n",
       "      <th>G1.1</th>\n",
       "      <th>G1.2</th>\n",
       "      <th>sn</th>\n",
       "      <th>monthly_mean_air_temperature</th>\n",
       "      <th>G1.3</th>\n",
       "      <th>sn.1</th>\n",
       "      <th>...</th>\n",
       "      <th>iw</th>\n",
       "      <th>fx</th>\n",
       "      <th>yfx</th>\n",
       "      <th>G4.6</th>\n",
       "      <th>Dts</th>\n",
       "      <th>Dgr</th>\n",
       "      <th>G4.7</th>\n",
       "      <th>iy</th>\n",
       "      <th>Gx</th>\n",
       "      <th>Gn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013</td>\n",
       "      <td>4</td>\n",
       "      <td>1001</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013</td>\n",
       "      <td>4</td>\n",
       "      <td>1007</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013</td>\n",
       "      <td>4</td>\n",
       "      <td>1008</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013</td>\n",
       "      <td>4</td>\n",
       "      <td>1025</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013</td>\n",
       "      <td>4</td>\n",
       "      <td>1026</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 91 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  month  station_id   G1  G1.1  G1.2   sn  \\\n",
       "0  2013      4        1001  1.0   2.0   3.0  1.0   \n",
       "1  2013      4        1007  1.0   2.0   3.0  1.0   \n",
       "2  2013      4        1008  1.0   2.0   3.0  1.0   \n",
       "3  2013      4        1025  1.0   2.0   3.0  0.0   \n",
       "4  2013      4        1026  1.0   2.0   3.0  0.0   \n",
       "\n",
       "   monthly_mean_air_temperature  G1.3  sn.1  ...  iw  fx  yfx  G4.6  Dts  Dgr  \\\n",
       "0                          42.0   4.0   1.0  ... NaN NaN  NaN   NaN  NaN  NaN   \n",
       "1                          92.0   4.0   1.0  ... NaN NaN  NaN   NaN  NaN  NaN   \n",
       "2                          93.0   4.0   1.0  ... NaN NaN  NaN   NaN  NaN  NaN   \n",
       "3                          10.0   4.0   0.0  ... NaN NaN  NaN   NaN  NaN  NaN   \n",
       "4                          12.0   4.0   0.0  ... NaN NaN  NaN   NaN  NaN  NaN   \n",
       "\n",
       "   G4.7  iy  Gx  Gn  \n",
       "0   NaN NaN NaN NaN  \n",
       "1   NaN NaN NaN NaN  \n",
       "2   NaN NaN NaN NaN  \n",
       "3   NaN NaN NaN NaN  \n",
       "4   NaN NaN NaN NaN  \n",
       "\n",
       "[5 rows x 91 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove columns\n",
    "reports_data_dropped = reports_data.drop(['Po', 'Po.1', 'P', 'P.1', 'T.1', 'st', 'st.1', \n",
    "                                          'Tx.1', 'Tn.1', \n",
    "                                          'e', 'e.1', \n",
    "                                          'R1.1', 'nr.1', 'S1.1', 'Rd', 'mp', 'mT', 'mTx', 'mTn', 'me', 'mR', 'mS', \n",
    "                                            #   'sn', 'sn.1', 'sn.2', 'sn.3', 'sn.4', 'sn.5', 'sn.6', 'sn.7', 'sn.8', 'sn.9',\n",
    "                                            # 'G1', 'G1.1', 'G1.2', 'G1.3', 'G1.4', 'G1.5', 'G1.6', 'G1.7', 'G1.8',\n",
    "                                            # 'G2', 'G2.1', 'G2.2', 'G2.3', 'G2.4', 'G2.5', 'G2.6', 'G2.7', 'G2.8', 'G2.9',\n",
    "                                            # 'G3', 'G3.1', 'G3.2', 'G3.3', 'G3.4', 'G3.5', 'G3.6', 'G3.7', 'G3.8', 'G3.9',\n",
    "                                            # 'G4', 'G4.1', 'G4.2', 'G4.3', 'G4.4', 'G4.5', 'G4.6', 'G4.7',\n",
    "                                            'Yb', 'Yc', 'P', 'YP', 'YR', 'YS', 'YT', 'YTx',\n",
    "                                            'Ye', 'G4', 'Txd', 'yx', 'Tnd', 'Tax', 'Tan' ], axis=1)\n",
    "\n",
    "# Drop columns with no data\n",
    "reports_data_dropped = reports_data_dropped.dropna(axis=1, how='all')\n",
    "\n",
    "# Rename columns\n",
    "reports_data_renamed = reports_data_dropped.rename(columns={'IIiii':'station_id', 'T':'monthly_mean_air_temperature', \n",
    "                                            'Tx':'mean_daily_maximum_air_temperature', \n",
    "                                            'Tn':'mean_daily_minimum_air_temperature', \n",
    "                                            'R1':'total_precipitation_month', 'S1':'total_sunshine_month', \n",
    "                                            'ps':'percentage_total_sunshine_duration_relative_normal', \n",
    "                                            'P0':'monthly_mean_pressure_station_level', 'e':'mean_vapor_pressure_month', \n",
    "                                            'nr':'number_days_month_precipitation', \n",
    "                                            'yP':'missing_years_air_pressure', 'yR':'missing_years_precipitation', 'yS':'missing_years_sunshine_duration', \n",
    "                                            'yT':'missing_years_mean_air_temperature', 'yTx':'missing_years_mean_extreme_air_temperature', 'ye':'missing_years_vapor_pressure', \n",
    "                                            'T25':'days_month_maximum_air_temperature_25', 'T30':'days_month_maximum_air_temperature_30', \n",
    "                                            'T35':'days_month_maximum_air_temperature_35', 'T40':'days_month_maximum_air_temperature_40', \n",
    "                                            'Tn0':'days_month_minimum_air_temperature_0', 'Tx0':'days_month_maximum_air_temperature_0', 'R01':'days_month_precipitation_1', \n",
    "                                            'R05':'days_month_precipitation_5', 'R10':'days_month_precipitation_10', 'R50':'days_month_precipitation_50', \n",
    "                                            'R100':'days_month_precipitation_100', 'R150':'days_month_precipitation_150', 's00':'days_month_snow_depth_0', \n",
    "                                            's01':'days_month_snow_depth_1', 's10':'days_month_snow_depth_10', 's50':'days_month_snow_depth_50', 'f10':'days_month_wind_speed_10', \n",
    "                                            'f20':'days_month_wind_speed_20', 'f30':'days_month_wind_speed_30', 'V1':'days_month_visibility_50', 'V2':'days_month_visibility_100', \n",
    "                                            'V3':'days_month_visibility_1000', 'yn': 'day_lowest_daily_mean_air_temperature_month', 'yax': 'day_highest_daily_mean_air_temperature_month', 'yan':'day_lowest_air_tempreature_month',\n",
    "                                            'Rx':'highest_daily_amount_precipitation_month_tenths_mm',  'yr':'day_highest_daily_amount_precipitation_month'})\n",
    "\n",
    "# Remove rows with missing values in [year]\n",
    "reports_data_renamed = reports_data_renamed.dropna(subset=['year'])\n",
    "\n",
    "# Enconde Year, Month, and Station ID to integer\n",
    "reports_data_renamed['year'] = reports_data_renamed['year'].astype(int)\n",
    "reports_data_renamed['month'] = reports_data_renamed['month'].astype(int)\n",
    "reports_data_renamed['station_id'] = reports_data_renamed['station_id'].astype(int)\n",
    "\n",
    "# # Show null values\n",
    "# print(reports_data_renamed.isnull().sum())\n",
    "\n",
    "reports_data_renamed.to_csv('DataS1/monthly-climat-reports-from-stations-worldwide-cleaned.csv', index=False)\n",
    "\n",
    "reports_data_renamed.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_id</th>\n",
       "      <th>station_name</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>height</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01001</td>\n",
       "      <td>Jan Mayen</td>\n",
       "      <td>70.94</td>\n",
       "      <td>-08.67</td>\n",
       "      <td>9</td>\n",
       "      <td>Norway                                       ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01005</td>\n",
       "      <td>Isfjord Radio</td>\n",
       "      <td>78.06</td>\n",
       "      <td>13.63</td>\n",
       "      <td>9</td>\n",
       "      <td>Norway                                       ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01007</td>\n",
       "      <td>Ny-Alesund</td>\n",
       "      <td>78.92</td>\n",
       "      <td>11.93</td>\n",
       "      <td>8</td>\n",
       "      <td>Norway                                       ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01008</td>\n",
       "      <td>Svalbard</td>\n",
       "      <td>78.25</td>\n",
       "      <td>15.50</td>\n",
       "      <td>27</td>\n",
       "      <td>Norway                                       ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01025</td>\n",
       "      <td>Tromso/Langnes</td>\n",
       "      <td>69.68</td>\n",
       "      <td>18.91</td>\n",
       "      <td>9</td>\n",
       "      <td>Norway                                       ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  station_id              station_name  \\\n",
       "0      01001                 Jan Mayen   \n",
       "1      01005             Isfjord Radio   \n",
       "2      01007                Ny-Alesund   \n",
       "3      01008                  Svalbard   \n",
       "4      01025            Tromso/Langnes   \n",
       "\n",
       "                                      latitude   longitude   height  \\\n",
       "0                                        70.94      -08.67        9   \n",
       "1                                        78.06       13.63        9   \n",
       "2                                        78.92       11.93        8   \n",
       "3                                        78.25       15.50       27   \n",
       "4                                        69.68       18.91        9   \n",
       "\n",
       "                                             country  \n",
       "0   Norway                                       ...  \n",
       "1   Norway                                       ...  \n",
       "2   Norway                                       ...  \n",
       "3   Norway                                       ...  \n",
       "4   Norway                                       ...  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stations_data.dtypes\n",
    "\n",
    "# Rename columns\n",
    "# 0: Station ID, 1: Station Name, 2: Latitude, 3: Longitude, 4:Height, 5: Country\n",
    "stations_data = stations_data.rename(columns={'0':'station_id', '1':'station_name', '2':'latitude', '3':'longitude', '4':'height', '5':'country'})\n",
    "\n",
    "stations_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# avg_prec = pd.read_csv('DataS1/average-precipitation-per-year.csv')\n",
    "# avg_prec.drop(['Code'], axis=1, inplace=True)\n",
    "# avg_prec.rename(columns={'Entity':'country', 'Year':'year'}, inplace=True)\n",
    "# avg_prec.head()\n",
    "\n",
    "# # Merge the two datasets by Country\n",
    "# data_merged = pd.merge(data_fe, avg_prec, on=['country', 'year'], how='left')\n",
    "# data_merged.head()\n",
    "\n",
    "# # Save\n",
    "# data_merged.to_csv('DataS1/jaguar_movement_data_cleaned.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Feature Engineering\n",
    " Environmental Features:\n",
    " Integrate meteorological data (e.g., temperature, rainfall) if available.\n",
    " Integrate terrain data (e.g., elevation, land cover type) if available.\n",
    " Temporal Features:\n",
    " Extract time of day, day of week, and season from the timestamp.\n",
    " Identify specific behavioral periods like night vs. day.<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Labeling the Data\n",
    " Behavior Labeling:\n",
    " Manually label a subset of data with different behaviors (e.g., movement, hunting, resting).\n",
    " Consider cross-referencing domain knowledge or complementary data to infer labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Model Selection\n",
    " Choose Algorithms:\n",
    " Evaluate models like Random Forest, Gradient Boosting Machines (e.g., XGBoost), or neural networks (RNN/LSTM for sequential data).\n",
    " Decide on the best model based on data type and problem complexity.\n",
    " Split Data:\n",
    " Split the data into training and testing sets (e.g., 80/20 or 70/30 split)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Model Training and Evaluation\n",
    " Train Models:\n",
    " Train selected models using the preprocessed data.\n",
    " Use cross-validation to tune model parameters.\n",
    " Evaluate Model:\n",
    " Evaluate performance using metrics like accuracy, precision, recall, and F1-score.\n",
    " If the dataset is imbalanced, apply techniques like SMOTE to balance it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Cross-Referencing with Complementary Data\n",
    " Integrate Meteorological Data:\n",
    " Merge weather data (e.g., temperature, humidity) with animal tracking data.\n",
    " Integrate Terrain Data:\n",
    " Merge terrain data (e.g., elevation, land use) with animal tracking data.\n",
    " Behavioral Biology Data:\n",
    " Incorporate knowledge from related behavioral biology studies (if available)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Model Deployment\n",
    " Model Evaluation: Confirm that the model generalizes well to new or unseen data.\n",
    " Deploy Model:\n",
    " Prepare the model for deployment in a real-time or batch setting for wildlife tracking.\n",
    " Implement a user interface or tool to apply the model to new data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
